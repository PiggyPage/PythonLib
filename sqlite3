[Python标准库]sqlite3——嵌入式关系数据库
    作用：实现一个嵌入式关系数据库，并提供 SQL 支持。
    Python 版本：2.5 及以后版本
    sqlite3 模块为 SQLite 提供了一个 DB-API 2.0 兼容接口，SQLite 是一个进程中关系数据库。SQLite 设计为嵌入在应用中，而不是像 MySQL、PostgreSQL 或 Oracle 使用一个单独的数据库服务器程序。SQLite 的速度很快、经过了严格的测试，而且很灵活，所以非常适合为一些应用建立原型和生产部署。
创建数据库
    SQLite 数据库作为一个文件存储在文件系统中。这个库管理对文件的访问，包括加锁来防止多个书写器使用它时造成破坏。数据库在第一次访问文件时创建，不过应用要负责管理数据库中的数据库表定义，即模式（schema）。
    下面这个例子在用 connect() 打开数据库文件之前先查找这个文件，以便了解何时为新数据库创建模式。

import os
import sqlite3

db_filename = 'todo.db'

db_is_new = not os.path.exists(db_filename)

conn = sqlite3.connect(db_filename)

if db_is_new:
    print 'Need to create schema'
else:
    print 'Database exists, assume schema dose, too.'

conn.close()

    将这个脚本运行两次，可以看到，如果文件尚不存在则会创建空文件。
    创建新的数据库文件后，下一步是创建模式来定义数据库中的表。这一节余下的例子使用的数据库模式与管理任务的表相同。数据库模式的详细信息见下表：
                      “project” 表
    --------------------------------------------------
          列      |  类型   |           描述
    --------------------------------------------------
      name        |  text  |  项目名
    --------------------------------------------------
      description |  text  |  详细的项目描述
    --------------------------------------------------
      deadline    |  date  |  整个项目的预定结束日期
    --------------------------------------------------

                          “task” 表
    ----------------------------------------------------------------
          列      |   类型    |                  描述
    ----------------------------------------------------------------
      id          |  number  |  唯一任务标识
    ----------------------------------------------------------------
      priority    |  integer |  优先级数值：值越小越重要
    ----------------------------------------------------------------
      details     |  text    |  完备的任务详细描述
    ----------------------------------------------------------------
      status      |  text    |  任务状态[new/pending/done/canceled]
    ----------------------------------------------------------------
      deadline    |  date    |  这个任务的预定结束日期
    ----------------------------------------------------------------
      completed_on|  date    |  任务何时完成
    ----------------------------------------------------------------
      project     |  text    |  这个任务对应的项目名
    ----------------------------------------------------------------
    以下是创建这些表的数据定义语言（data definition language, DDL）语句。

-- Schema for to-do application examples.

-- Projects are high-level activities made up of tasks
create table project (
    name        text primary key,
    description text,
    deadline    date
);

-- Task are steps that can be taken to complete a project
create table task (
    id           integer primary key autoincrement not null,
    priority     integer default 1,
    details      text,
    status       text,
    deadline     date,
    completed_on date,
    project      text not null references project(name)
);
    可以用 Connection 的 executescript() 方法来运行创建模式的 DDL 指令。

import os
import sqlite3

db_filename = 'todo.db'
schema_filename = 'todo_schema.sql'

db_is_new = not os.path.exists(db_filename)

with sqlite3.connect(db_filename) as conn:
    if db_is_new:
        print 'Creating schema'
        with open(schema_filename, 'rt') as f:
            schema = f.read()
        conn.executescript(schema)

        print 'Inserting initial data'

        conn.executescript(
            """
            insert into project (name, description, deadline)
            values ('pymotw', 'Python Module of the Week', '2010-11-01');
            insert into task (details, status, deadline, project)
            values ('write about select', 'done', '2010-10-03', 'pymotw');
            insert into task (details, status, deadline, project)
            values ('write about random', 'waiting', '2010-10-10', 'pymotw');
            insert into task (details, status, deadline, project)
            values ('write about sqlite3', 'active', '2010-10-17', 'pymotw');
            """
            )
    else:
        print 'Database exists, assume schema does, too.'

    创建这些数据表之后，用一些插入语句创建一个示例项目和相关的任务。可以用 sqlite3 命令行程序检查数据库的内容。
获取数据
    要从一个 Python 程序中获取 task 表中保存的值，可以从数据库连接创建一个 cursor。游标（cursor）会生成一个一致的数据视图，这也是与类似 SQLite 的事务型数据库系统交互的主要方式。

import sqlite3

db_filename = 'todo.db'

with sqlite3.connect(db_filename) as conn:
    cursor = conn.cursor()

    cursor.execute(
        """
        select id, priority, details, status, deadline from task
        where project = 'pymotw'
        """
        )

    for row in cursor.fetchall():
        task_id, priority, details, status, deadline = row
        print '%2d {%d} %-20s [%-8s] (%s)' % \
              (task_id, priority, details, status, deadline)

    查询过程包括两步。首先，用游标的 execute() 方法运行查询，告诉数据库引擎要收集哪些数据。然后，使用 fetchall() 获取结果。返回值是一个元组序列，元组中包含查询 select 子句中所包括的列的值。
    可以用 fetchone() 一次获取一个结果，也可以用 fetchmany() 获取固定大小的批量结果。

import sqlite3

db_filename = 'todo.db'

with sqlite3.connect(db_filename) as conn:
    cursor = conn.cursor()

    cursor.execute(
        """
        select name, description, deadline from project
        where name = 'pymotw'
        """
        )
    name, description, deadline = cursor.fetchone()
    print 'Project details for %s (%s) due %s' % \
              (description, name, deadline)

    cursor.execute(
        """
        select id, priority, details, status, deadline from task
        where project = 'pymotw' order by deadline
        """
        )

    print '\nNext 5 tasks:'
    for row in cursor.fetchmany(5):
        task_id, priority, details, status, deadline = row
        print '%2d {%d} %-25s [%-8s] (%s)' % \
              (task_id, priority, details, status, deadline)

    传入 fetchmany() 的值是要返回的最大元素数。如果没有提供足够的元素，返回的序列大小将小于这个最大值。
查询元数据
    DB-API 2.0 规范指出：调用 execute() 之后，cursor 应当设置其 description 属性，来保存将由 fetch 方法返回的数据的有关信息。API 规范指出这个描述值是一个元组序列，各元组包含列名、类型、显示大小、内部大小、精度、范围和一个指示是否接受 null 值的标志。

import sqlite3

db_filename = 'todo.db'

with sqlite3.connect(db_filename) as conn:
    cursor = conn.cursor()

    cursor.execute(
        """
        select * from task where project = 'pymotw'
        """
        )

    print 'Task table has these columns:'
    for coinfo in cursor.description:
        print coinfo

    由于 sqlite3 对插入到数据库的数据没有类型或大小约束，所以只填入列名值。
行对象
    默认情况下，获取方法从数据库作为“行”返回的值是元组。调用者负责了解查询中列的顺序，并从元组中抽取单个的值。查询的值个数增加时，或者处理数据的代码分布在一个库的不同位置时，通常更容易的做法是处理一个对象，并使用其列名来访问值。这样一来，编辑查询时，元组内容的个数和顺序可以随时间改变，另外依赖于查询结果的代码也不太可能出问题。
    Connection 对象有一个 row_factory 属性，允许调用代码控制所创建对象的类型来表示查询结果集中的各行。sqlite3 还包括一个 Row 类，这个类将用作一个行工厂。可以通过 Row 实例使用列索引或名来访问列值。

import sqlite3

db_filename = 'todo.db'

with sqlite3.connect(db_filename) as conn:
    # Change the row factory to use Row
    conn.row_factory = sqlite3.Row
    
    cursor = conn.cursor()

    cursor.execute(
        """
        select name, description, deadline from project
        where name = 'pymotw'
        """
        )
    name, description, deadline = cursor.fetchone()
    
    print 'Project details for %s (%s) due %s' % (
        description, name, deadline)
    
    cursor.execute(
        """
        select id, priority, details, status, deadline from task
        where project = 'pymotw' order by deadline
        """
        )

    print '\nNext 5 tasks:'
    for row in cursor.fetchmany(5):
        print '%2d {%d} %-25s [%-8s] (%s)' % (
            row['id'], row['priority'], row['details'],
            row['status'], row['deadline'],
            )

    这个版本的例子重写为使用 Row 实例而不是元组。打印 project 表中的行时仍然通过位置来访问列值，不过打印任务的 print 语句使用了关键字查找，所以任务查询中列顺序的该表并不会有任何影响。
查询中使用变量
    如果查询定义为字面量字符串嵌入到程序中，使用这种查询很不灵活。例如，向数据库添加另一个项目时，显示前 5 个任务的查询就应当更新，以处理其中某一个项目。要想增加灵活性，一种方法是建立一个 SQL 语句，通过在 Python 中结合相应的值来得到所需的查询。不过，以这种方式构造查询串很危险，应当尽量避免。如果未能对查询中可变部分的特殊字符正确转义，可能会导致 SQL 解析错误，或者更糟糕的是，还有可能导致一个安全漏洞，称为 SQL 注入攻击（SQL-injection attack），这使得入侵者可以在数据库中执行任意的 SQL 语句。
    要在查询中使用动态值，正确的方法是利用随 SQL 指令一起传入 execute() 的宿主变量（host variable）。SQL 语句执行时，语句中的占位符值会替换为宿主变量的值。通过使用宿主变量，而不是解析之前在 SQL 语句中插入任意的值，这样可以避免注入攻击，因为不可信的值没有机会影响 SQL 语句的解析。SQLite 支持两种形式带占位符的查询，分别是位置参数和命名参数。
    1. 位置参数
    问号（?）指示一个位置参数，将作为元组的一个成员传至 execute()。

import sqlite3
import sys

db_filename = 'todo.db'
project_name = sys.argv[1]

with sqlite3.connect(db_filename) as conn:
    cursor = conn.cursor()
    query = """select id, priority, details, status, deadline from task
            where project = ?
            """

    cursor.execute(query, (project_name,))

    for row in cursor.fetchall():
        task_id, priority, details, status, deadline = row
        print '%2d {%d} %-20s [%-8s] (%s)' % (
            task_id, priority, details, status, deadline)

    命令行参数会作为位置参数安全地传至查询，所以恶意数据不可能破坏数据库。
    2. 命名参数
    对于包含大量参数的更为复杂的查询，或者如果查询中某些参数会重复多次，则可以使用命名参数。命令参数前面有一个冒号作为前缀（例如，:param_name）。

import sqlite3
import sys

db_filename = 'todo.db'
project_name = sys.argv[1]

with sqlite3.connect(db_filename) as conn:
    cursor = conn.cursor()
    query = """select id, priority, details, status, deadline from task
            where project = :project_name
            order by deadline, priority
            """

    cursor.execute(query, {'project_name':project_name})

    for row in cursor.fetchall():
        task_id, priority, details, status, deadline = row
        print '%2d {%d} %-20s [%-8s] (%s)' % (
            task_id, priority, details, status, deadline)

    位置或命名参数都不需要加引号或转义，因为查询解析器会对它们做特殊处理。
    查询参数可以在 select（选择）、insert（插入）和 update（更新）语句中使用。查询中字面量能够出现的位置都可以放置查询参数。

import sqlite3
import sys

db_filename = 'todo.db'
id = int(sys.argv[1])
status = sys.argv[2]

with sqlite3.connect(db_filename) as conn:
    cursor = conn.cursor()
    query = "update task set status = :status where id = :id"
    cursor.execute(query, {'status':status, 'id':id})

    这个 update 语句使用了两个命名参数。id 值用于查找要修改的行，status 值则要写入数据表。
批量加载
    要对一个很大的数据集应用相同的 SQL 指令，可以使用 executemany()。这对于加载数据很有用，因为这样可以避免在 Python 中循环处理输入，而是让底层库对循环应用一些优化。下面这个示例程序使用 csv 模块从一个逗号分隔值文件读取任务列表，并将其加载到数据库。

import csv
import sqlite3
import sys

db_filename = 'todo.db'
data_filename = sys.argv[1]

SQL = """
      insert into task (details, priority, status, deadline, project)
      values (:details, :priority, 'active', :deadline, :project)
      """

with open(data_filename, 'rt') as csv_file:
    csv_reader = csv.DictReader(csv_file)

    with sqlite3.connect(db_filename) as conn:
        cursor = conn.cursor()
        cursor.executemany(SQL, csv_reader)

    示例数据文件 tasks.csv 包含以下数据:
    deadline,project,priority,details
    2010-10-02,pymotw,2,"finish reviewing markup"
    2010-10-03,pymotw,2,"revise chapter intros"
    2010-10-03,pymotw,3,"subtitle"
定义新列类型
    SQLite 对整数、浮点数和文本列提供了内置支持。sqlite3 会自动将这些类型的数据从 Python 的表示转换为可在数据库中存储的一个值，还可以根据需要从数据库中存储的值转换回 Python 的表示。整数值由数据库加载为 int 或 long 变量，这取决于值的大小。文本将作为 unicode 保存和获取（除非改变了 Connection 的 text_factory）。
    尽管 SQLite 在内部只支持几种数据类型，不过 sqlite3 包括了一些便利工具，可以定义定制类型，允许 Python 应用在列中存储任意类型的数据。除了那些得到默认支持的类型外，还可以在数据库连接中使用 detect_types 标志启用其他类型。如果定义表时列使用所要求的类型来声明，可以使用 PARSE_DECLTYPES。

import sqlite3
import sys

db_filename = 'todo.db'

sql = "select id, details, deadline from task"

def show_deadline(conn):
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    cursor.execute(sql)
    row = cursor.fetchone()
    for col in ['id', 'details', 'deadline']:
        print '  %-8s  %-30r %s' % (col, row[col], type(row[col]))
    return

print 'Without type detection:'
with sqlite3.connect(db_filename) as conn:
    show_deadline(conn)

print '\nWith type detection'
with sqlite3.connect(db_filename,
                     detect_types=sqlite3.PARSE_DECLTYPES,
                     ) as conn:
    show_deadline(conn)

    sqlite3 为日期和时间戳列提供了转换器，它使用 datetime 模块的 date 和 datetime 表示 Python 中的值。这两个与日期有关的转换器会在打开类型检测时自动启用。
    定义一个新类型需要注册两个函数。适配器（adapter）取 Python 对象作为输入，返回一个可以存储在数据库中的字节串。转换器（converter）从数据库接收串，返回一个 Python 对象。要使用 register_adapter() 定义适配器函数，使用 register_converter() 定义转换器函数。

import sqlite3
try:
    import cPickle as pickle
except:
    import pickle

db_filename = 'todo.db'

sql = "select id, details, deadline from task"

def adapter_func(obj):
    """Convert from in-memory to storage representation."""
    print 'adapter_func(%s)\n' % obj
    return pickle.dumps(obj)

def converter_func(data):
    """Convert from storage to in-memory representation."""
    print 'converter_func(%r)\n' % data
    return pickle.loads(data)

class MyObj(object):
    def __init__(self, arg):
        self.arg = arg
    def __str__(self):
        return 'MyObj(%r)' % self.arg

# Register the functions for manipulating the type.
sqlite3.register_adapter(MyObj, adapter_func)
sqlite3.register_converter("MyObj", converter_func)

# Create some objects to save.  Use a list of tuples so
# the sequence can be passed directly to executemany().
to_save = [ (MyObj('this is a value to save'),),
            (MyObj(42),),
            ]

with sqlite3.connect(db_filename,
                     detect_types=sqlite3.PARSE_DECLTYPES) as conn:
    # Create a table with column of type "MyObj"
    conn.execute("""
    create table if not exists obj (
        id    integer primary key autoincrement not null,
        data  MyObj
    )
    """)
    cursor = conn.cursor()

    # Insert the objects into the database
    cursor.executemany("insert into obj (data) values (?)", to_save)

# Query the database for the objects just saved
cursor.execute("select id, data from obj")
for obj_id, obj in cursor.fetchall():
    print 'Retrieved', obj_id, obj, type(obj)
    print

    这个例子使用 pickle 将一个对象保存为可以存储在数据库中的串，这对于存储任意的对象很有用，不过这种技术不支持按对象属性查询。正真的对象关系映射器（object-relational mapper，如 SQLAlchemy）可以将属性值存储在单独的列中，这对于大量数据更为有用。
确定列类型
    查询返回的值的类型信息有两个来源。可以用原表声明来识别一个实际列的类型，这在前面已经看到。另外还可以在查询自身的 select 子句中包含类型指示符，采用以下形式：as "name[type]"。

import sqlite3
try:
    import cPickle as pickle
except:
    import pickle

db_filename = 'todo.db'

sql = "select id, details, deadline from task"

def adapter_func(obj):
    """Convert from in-memory to storage representation."""
    print 'adapter_func(%s)\n' % obj
    return pickle.dumps(obj)

def converter_func(data):
    """Convert from storage to in-memory representation."""
    print 'converter_func(%r)\n' % data
    return pickle.loads(data)

class MyObj(object):
    def __init__(self, arg):
        self.arg = arg
    def __str__(self):
        return 'MyObj(%r)' % self.arg

# Register the functions for manipulating the type.
sqlite3.register_adapter(MyObj, adapter_func)
sqlite3.register_converter("MyObj", converter_func)

# Create some objects to save.  Use a list of tuples so
# the sequence can be passed directly to executemany().
to_save = [ (MyObj('this is a value to save'),),
            (MyObj(42),),
            ]

with sqlite3.connect(db_filename,
                     detect_types=sqlite3.PARSE_DECLTYPES) as conn:
    # Create a table with column of type "MyObj"
    conn.execute("""
    create table if not exists obj2 (
        id    integer primary key autoincrement not null,
        data  MyObj
    )
    """)
    cursor = conn.cursor()

    # Insert the objects into the database
    cursor.executemany("insert into obj2 (data) values (?)", to_save)

# Query the database for the objects just saved
cursor.execute('select id, data as "pickle [MyObj]" from obj2')
for obj_id, obj in cursor.fetchall():
    print 'Retrieved', obj_id, obj, type(obj)
    print

    如果类型是查询的一部分而不属于原表定义，则要使用 detect_types 标志 PARSE_COLNAMES。
事务
    关系型数据库的关键特性之一是使用事务（transaction）维护一致的内部状态。启用事务时，在提交结果并刷新输出到真正的数据库之前，可以通过一个连接完成多个变更，而不会影响任何其他用户。
    1. 保留变更
    不论通过插入（insert）还是更新（update）语句改变数据库，都需要显式地调用 commit() 保存这些变更。这个要求为应用提供了一个机会，可以将多个相关的变更一同完成，使它们以一种“原子”方式保存而不是增量保存，这样可以避免同时连接到数据库的不同客户只看到部分更新的情况。
    可以利用一个使用了多个数据库连接的程序来查看调用 commit() 的效果。用第一个连接插入一个新行，然后两次尝试使用不同的连接读回这个数据行。

import sqlite3

db_filename = 'todo.db'

def show_projects(conn):
    cursor = conn.cursor()
    cursor.execute('select name, description from project')
    for name, desc in cursor.fetchall():
        print '  ', name
    return

with sqlite3.connect(db_filename) as conn1:

    print 'Before changes:'
    show_projects(conn1)

    # Insert in one cursor
    cursor1 = conn1.cursor()
    cursor1.execute("""
    insert into project (name, description, deadline)
    values ('virtualenvwrapper', 'Virtualenv Extensions',
            '2011-01-01')
    """)

    print '\nAfter changes in conn1:'
    show_projects(conn1)

    # Select from another connection, without committing first
    print '\nBefore commit:'
    with sqlite3.connect(db_filename) as conn2:
        show_projects(conn2)

        # Commit then select from another connection
        conn1.commit()
        print '\nAfter commit:'
        with sqlite3.connect(db_filename) as conn3:
            show_projects(conn3)

    提交 conn1 之前调用 show_projects() 时，其结果取决于使用了哪个连接。由于这个改变通过 conn1 完成，它会看到修改后的数据。不过，conn2 看不到这个改变。提交之后，新连接 conn3 会看到插入的行。
    2. 丢弃变更
    还可以使用 rollback() 完全丢弃未提交的变更。commit() 和 rollback() 方法通常在同一个 try:except 块的不同部分调用，有错误时就会触发回滚。

import sqlite3

db_filename = 'todo.db'

def show_projects(conn):
    cursor = conn.cursor()
    cursor.execute('select name, description from project')
    for name, desc in cursor.fetchall():
        print '  ', name
    return

with sqlite3.connect(db_filename) as conn:

    print 'Before changes:'
    show_projects(conn)
    try:
        # Insert in one cursor
        cursor = conn.cursor()
        cursor.execute("""delete from project
                       where name = 'virtualenvwrapper'
                       """)

        # Show the settings
        print '\nAfter delete:'
        show_projects(conn)

        # Pretend the processing caused an error
        raise RuntimeError('simulated error')

    except Exception, err:
        # Discard the changes
        print 'ERROR:', err
        conn.rollback()

    else:
        # Save the changes
        conn.commit()

    print '\nAfter rollback:'
    show_projects(conn)

    调用 rollback() 后，对数据库的修改不复存在。
隔离级别
    sqlite3 支持 3 种加锁模式，也称为隔离级别（isolation level），这会控制使用何种技术避免连接之间不兼容的变更。打开一个连接时可以传入一个字符串作为 isolation_level 参数来设置隔离级别，所以不同的连接可以使用不同的隔离级别值。
    下面这个程序展示了使用同一个数据库的不同连接时，不同的隔离级别对于线程中事件的顺序会有什么影响。这里创建 4 个线程。两个线程会更新现有的行，将变更写入数据库。另外两个线程尝试从 task 表读取所有行。

import sqlite3
import logging
import sys
import threading
import time

logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s (%(threadName)-10s) %(message)s',
    )

db_filename = 'todo.db'
isolation_level = sys.argv[1]

def writer():
    my_name = threading.currentThread().name
    with sqlite3.connect(db_filename,
                         isolation_level=isolation_level) as conn:
        cursor = conn.cursor()
        cursor.execute('update task set priority = priority + 1')
        logging.debug('waiting to synchronize')
        ready.wait() # synchronize threads
        logging.debug('PAUSING')
        time.sleep(1)
        conn.commit()
        logging.debug('CHANGES COMMITTED')
    return

def reader():
    my_name = threading.currentThread().name
    with sqlite3.connect(db_filename,
                         isolation_level=isolation_level) as conn:
        cursor = conn.cursor()
        logging.debug('waiting to synchronize')
        ready.wait() # synchronize threads
        logging.debug('wait over')
        cursor.execute('select * from task')
        logging.debug('SELECT EXECUTED')
        results = cursor.fetchall()
        logging.debug('results fetched')
    return

if __name__ == '__main__':
    ready = threading.Event()

    threads = [
        threading.Thread(name='Reader 1', target=reader),
        threading.Thread(name='Reader 2', target=reader),
        threading.Thread(name='Writer 1', target=writer),
        threading.Thread(name='Writer 2', target=writer),
        ]

    [ t.start() for t in threads ]

    time.sleep(1)
    logging.debug('setting ready')
    ready.set()

    [ t.join() for t in threads ]

    这些线程使用 threading 模块的一个 Event 完成同步。writer() 函数连接数据库，并完成数据库修改，不过在事件触发前并不提交。reader() 函数连接数据库，然后等待查询数据库，知道出现同步事件。
    1. 延迟
    默认的隔离级别是 DEFERRED。使用延迟（Deferred）模块会锁定数据库，但只是在修改真正开始时锁定一次。前面的所有例子都使用了延迟模式。
    2. 立即
    采用立即（Immediate）模式时，修改一开始时就会锁定数据库，从而在事务提交之前避免其他游标修改数据库。如果数据库有复杂的写操作，但是阅读器比书写器更多，这种模式就非常适合，因为事务进行中不会阻塞阅读器。
    3. 互斥
    互斥（Exclusive）模式会对所有阅读器和书写器锁定数据库。如果数据库性能很重要，这种情况下就要限制使用这种模式，因为每个互斥的连接都会阻塞所有其他用户。
    如果第一个书写器已经开始修改，阅读器和第二个书写器会阻塞，直到第一个书写器提交。sleep() 调用在书写器线程中引入一个人为的延迟，以强调其他连接已阻塞这一事实。
    4. 自动提交
    连接的 isolation_level 参数还可以设置为 None，以启用自动提交（autocommit）模式。启用自动提交时，每个 execute() 调用会在语句完成时立即提交。自动提交模式很适合简短的事务，如向一个表插入少量数据。数据库锁定时间尽可能短，所以线程间竞争的可能性更小。
    sqlite3_autocommit.py 中删除了 commit() 的显式调用，并将隔离级别设置为 None，不过除此以外，其他内容都与 sqlite3_isolation_levels.py 相同。但输出是不同的，因为两个书写器线程会在阅读器开始查询之前完成工作。
内存中数据库
    SQLite 支持在 RAM 中管理整个数据库，而不是依赖一个磁盘文件。如果测试运行之间不需要保留数据库，或者要尝试一个模式或其他数据库特性，此时内存中数据库对于自动测试会很有用。要打开一个内存中数据库，创建 Connection 时可以使用串 ':memory:' 而不是一个文件名。每个 ':memory:' 连接会创建一个单独的数据库实例，所以一个连接中游标所做的修改不会影响其他连接。
导出数据库内容
    内存中数据库的内容可以使用 Connection 的 iterdump() 方法保存。iterdump() 方法返回的迭代器生成一系列字符串，这些字符串将共同构造相应的 SQL 指令来重新创建数据库的状态。

import sqlite3

schema_filename = 'todo_schema.sql'

with sqlite3.connect(':memory:') as conn:
    conn.row_factory = sqlite3.Row

    print 'Creating schema'
    with open(schema_filename, 'rt') as f:
        schema = f.read()
    conn.executescript(schema)

    print 'Inserting initial data'
    conn.execute("""
        insert into project (name, description, deadline)
        values ('pymotw', 'Python Module of the Week', '2010-11-01')
        """)
    data = [
        ('write about select', 'done', '2010-10-03', 'pymotw'),
        ('write about random', 'waiting', '2010-10-10', 'pymotw'),
        ('write about sqlite3', 'active', '2010-10-17', 'pymotw'),
        ]
    conn.executemany("""
        insert into task (details, status, deadline, project)
        values (?, ?, ?, ?)
        """, data)

    print 'Dumping:'
    for text in conn.iterdump():
        print text

    iterdump() 也适用于保存到文件的数据库，不过对于未保存的数据库最为有用。这里对输出做了一些编辑调整，从而使其在保证语法正确的前提下适合在页面中显示。
SQL 中使用 Python 函数
    SQL 语法支持在查询中调用函数，可以在列列表中调用，也可以在 select 语句的 where 子句中调用。利用这个特性，从查询返回数据之前可以先处理数据，可以用于在不同格式之间转换、完成一些计算（否则使用纯 SQL 会很麻烦），以及重用应用代码。

import sqlite3

db_filename = 'todo.db'

def encrypt(s):
    print 'Encrypting %r' % s
    return s.encode('rot-13')

def decrypt(s):
    print 'Decrypting %r' % s
    return s.encode('rot-13')

with sqlite3.connect(db_filename) as conn:

    conn.create_function('encrypt', 1, encrypt)
    conn.create_function('decrypt', 1, decrypt)
    cursor = conn.cursor()

    # Raw values
    print 'Original values:'
    query = 'select id, details from task'
    cursor.execute(query)
    for row in cursor.fetchall():
        print row

    print '\nEncrypting...'
    query = 'update task set details = encrypt(details)'
    cursor.execute(query)
    print '\nRaw encrypted values:'
    query = 'select id, details from task'
    cursor.execute(query)
    for row in cursor.fetchall():
        print row
    print '\nDecrypting in query...'
    query = 'select id, decrypt(details) from task'
    cursor.execute(query)
    for row in cursor.fetchall():
        print row

    函数使用 Connection 的 create_function() 方法提供。参数包括函数名（即 SQL 中使用的函数名）、函数所取的参数个数，以及要提供的 Python 函数。
定制聚集
    聚集函数会收集多个单独的数据，并以某种方式汇总。avg()（取平均值）、min()、max() 和 count() 都是内置聚集函数的例子。
    sqlite3 使用的聚集器 API 定义为一个包含两个方法的类。处理查询时会对各个数据值分别调用一次 step() 方法。finalize() 方法在查询的最后调用一次，并返回聚集值。下面这个例子为 mode 实现了一个聚集器。它会返回输入中出现最频繁的值。

import sqlite3
import collections

db_filename = 'todo.db'

class Mode(object):
    def __init__(self):
        self.counter = collections.Counter()
    def step(self, value):
        print 'step(%r)' % value
        self.counter[value] += 1
    def finalize(self):
        result, count = self.counter.most_common(1)[0]
        print 'finalize() -> %r (%d times)' % (result, count)
        return result

with sqlite3.connect(db_filename) as conn:
    conn.create_aggregate('mode', 1, Mode)

    cursor = conn.cursor()
    cursor.execute("select mode(deadline) from task where project = 'pymotw'")
    row = cursor.fetchone()
    print 'mode(deadline) is:', row[0]

    聚集器类用 Connection 的 create_aggregate() 方法注册。参数包括函数名（即 SQL 中使用的函数名）、step() 方法所取得参数个数，以及要使用的类。
定制排序
    比对（collation）是一个比较函数，在 SQL 查询的 order by 部分使用。对于 SQLite 无法在内部排序的数据类型，可以使用定制比对来比较。例如，我们需要一个定制比对来对保存在 sqlite3_custom_type.py 中的 pickle 对象排序。

import sqlite3
try:
    import cPickle as pickle
except:
    import pickle

db_filename = 'todo.db'

def adapter_func(obj):
    return pickle.dumps(obj)
def converter_func(data):
    return pickle.loads(data)

class MyObj(object):
    def __init__(self, arg):
        self.arg = arg
    def __str__(self):
        return 'MyObj(%r)' % self.arg
    def __cmp__(self, other):
        return cmp(self.arg, other.arg)

# Register the functions for manipulating the type.
sqlite3.register_adapter(MyObj, adapter_func)
sqlite3.register_converter('MyObj', converter_func)

def collation_func(a, b):
    a_obj = converter_func(a)
    b_obj = converter_func(b)
    print 'collation_func(%s, %s)' % (a_obj, b_obj)
    return cmp(a_obj, b_obj)
    
with sqlite3.connect(db_filename,
                     detect_types=sqlite3.PARSE_DECLTYPES,
                     ) as conn:
    # Define the collation
    conn.create_collation('unpickle', collation_func)

    # Clear the table and insert new values
    conn.execute('delete from obj')
    conn.executemany('insert into obj (data) values (?)',
                     [(MyObj(x),) for x in xrange(5, 0, -1)],
                     )

    # Query the database for the objects just saved
    print 'Querying:'
    cursor = conn.cursor()
    cursor.execute("select id, data from obj order by data collate unpickle")
    for obj_id, obj in cursor.fetchall():
        print obj_id, obj

    对比函数的参数是字节串，所以在完成比较之前必须解除 pickle，并转换为 MyObj 实例。
线程和连接共享
    出于历史原因，由于必须使用老版本的 SQLite，Connection 对象不能在线程间共享。每个线程必须创建自己的数据库连接。

import sqlite3
import sys
import threading
import time

db_filename = 'todo.db'
isolation_level = None # autocommit mode

def reader(conn):
    my_name = threading.currentThread().name
    print 'Starting thread'
    try:
        cursor = conn.cursor()
        cursor.execute('select * from task')
        results = cursor.fetchall()
        print 'results fetached'
    except Exception, err:
        print 'ERROR:', err
    return

if __name__ == '__main__':

    with sqlite3.connect(db_filename,
                         isolation_level=isolation_level,
                         ) as conn:
        t = threading.Thread(name='Reader 1',
                             target=reader,
                             args=(conn,),
                             )
        t.start()
        t.join()

    如果试图在线程之间共享一个连接，这会导致一个异常。
限制对数据的访问
    与其他更大的关系数据库相比，尽管 SQLite 没用用户访问控制，但是确实提供了一种机制来限制列访问。每个连接可以安装一个授权函数（authorizer function），运行时可以根据所需的原则来批准或拒绝访问列。这个授权函数会在解析 SQL 语句时调用，将传入 5 个参数。第一个参数是一个动作码，只是所完成的操作的类型（读、写、删除等等）。其余的参数则取决于动作码。对于 SQLITE_READ 操作，这 4 个参数分别是表名、列名、SQL 语句中访问出现的位置（主查询、触发器等等）和 None。

import sqlite3

db_filename = 'todo.db'
def authorizer_func(action, table, column, sql_location, ignore):
    print '\nauthorizer_func(%s, %s, %s, %s, %s)' % \
          (action, table, column, sql_location, ignore)

    response = sqlite3.SQLITE_OK # be permissive by default

    if action == sqlite3.SQLITE_SELECT:
        print 'requesting permission to run a select statement'
        response = sqlite3.SQLITE_OK
    elif action == sqlite3.SQLITE_READ:
        print 'requesting access to column %s.%s from %s' % \
              (table, column, sql_location)
        if column == 'details':
            print '  ignoring details column'
            response = sqlite3.SQLITE_IGNORE
        elif column == 'priority':
            print '  preventing access to priority column'
            response = sqlite3.SQLITE_DENY

    return response

with sqlite3.connect(db_filename) as conn:
    conn.row_factory = sqlite3.Row
    conn.set_authorizer(authorizer_func)

    print 'Using SQLITE_IGNORE to mask a column value:'
    cursor = conn.cursor()
    cursor.execute("select id, details from task where project = 'pymotw'")
    for row in cursor.fetchall():
        print row['id'], row['details']

    print '\nUsing SQLITE_DENY to deny access to a column:'
    cursor = conn.cursor()
    cursor.execute("select id, priority from task where project = 'pymotw'")
    for row in cursor.fetchall():
        print row['id'], row['details']

    这个例子使用了 SQLITE_IGNORE，从而在查询结果中将从 task.details 列得到的串替换为 null 值。通过返回 SQLITE_DENY，还将避免对 task.priority 列的访问，如果尝试访问 task、priority 列，则会导致 SQLite 产生一个异常。
    sqlite3 中提供了一些可用的动作码，它们都作为常量提供，名字前都有前缀 SQLITE_。每一类 SQL 语句可以加标志，也可以控制对单个列的访问。